{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b634c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch\n",
    "import autograd.numpy as np\n",
    "import autograd.scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "from autograd.scipy.linalg import logm\n",
    "from autograd import grad, jacobian\n",
    "import numpy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ba79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09398f57",
   "metadata": {},
   "source": [
    "# Week 3 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7b93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(y, theta, d):\n",
    "    likelihood_cov = np.mean(np.square(y[0].T - theta.T @ d.T)) * np.eye(len(d))\n",
    "    likelihood_mean = d @ theta\n",
    "    return stable_multivariate_gaussian_logpdf(y[0].T, likelihood_mean, likelihood_cov)\n",
    "def stable_multivariate_gaussian_logpdf(x, mu, cov):\n",
    "    n = len(x)\n",
    "    x_mu = x - mu\n",
    "    try:\n",
    "        _, log_det = np.linalg.slogdet(cov)\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "        log_prob = -0.5 * (n * np.log(2 * np.pi) + log_det + np.dot(x_mu, np.dot(cov_inv, x_mu)))\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_modified = cov + np.eye(n) * 1e-8\n",
    "        _, log_det = np.linalg.slogdet(cov_modified)\n",
    "        cov_inv = np.linalg.inv(cov_modified)\n",
    "        log_prob = -0.5 * (n * np.log(2 * np.pi) + log_det + np.dot(x_mu, np.dot(cov_inv, x_mu)))\n",
    "    return log_prob\n",
    "\n",
    "\n",
    "def KLD(mean_q, A_q, mean_p, A_p):\n",
    "    sigma_q = (A_q @ A_q.T)\n",
    "    sigma_p = (A_p @ A_p.T)\n",
    "    bar_sigma_q = np.linalg.norm(sigma_q)\n",
    "    bar_sigma_p = np.linalg.norm(sigma_p)\n",
    "    k = len(mean_q)\n",
    "    return 0.5 * (np.trace(np.linalg.inv(sigma_p) @ sigma_q) + (mean_p - mean_q).T @ np.linalg.inv(sigma_p) @ (mean_p - mean_q) - k + np.log(bar_sigma_p/bar_sigma_q))\n",
    "\n",
    "def theta_to_params(theta):\n",
    "    shape = len(theta)\n",
    "    mean_shape = int(shape/3)\n",
    "    A_shape = (int(np.sqrt(shape - mean_shape)), int(np.sqrt(shape - mean_shape)))\n",
    "    mean = theta[0:mean_shape]\n",
    "    A = theta[mean_shape:shape].reshape(A_shape)\n",
    "    return mean, A\n",
    "\n",
    "def params_to_theta(mean, A):\n",
    "    return np.array(list(mean) + list(A.flatten()))\n",
    "\n",
    "def elbo(mean, A, y, d):\n",
    "    shape = d.shape[1]\n",
    "    values = []\n",
    "    while len(values) < 100:\n",
    "        sample = np.random.multivariate_normal(np.zeros(shape), np.eye(shape))\n",
    "        theta = mean + A @ sample\n",
    "        lik = log_likelihood(y, theta, d)\n",
    "        if np.any(np.isinf(lik)):\n",
    "            print('Skipped due to -inf found')\n",
    "            continue\n",
    "        values.append(lik)\n",
    "    return 1/(len(values))*np.sum(values) - KLD(mean, A, mean_prior, A_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a20a8b",
   "metadata": {},
   "source": [
    "# Important assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2a340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prior = np.array([[3.2, 1.6], [1.1, 2.9]])\n",
    "mean_prior = np.array([2, 5])\n",
    "cov_prior = A_prior @ A_prior.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815e6b9",
   "metadata": {},
   "source": [
    "# Utility functions needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774e4e5",
   "metadata": {},
   "source": [
    "## ~Likelihood~\n",
    "$$p(\\textbf{y}| \\theta_i, \\textbf{d})$$\n",
    "From PML notes, assumed to be gaussian $\\sim \\mathcal{N}(\\theta^T \\textbf{d}, \\sigma^2_\\textbf{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae58c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(y, theta, d):\n",
    "    MSE = np.mean(np.square(y - d @ theta))\n",
    "    likelihood_cov = MSE * np.eye(len(d))\n",
    "    likelihood_mean = d @ theta\n",
    "    return np.exp(stable_multivariate_gaussian_logpdf(y, likelihood_mean, likelihood_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccddbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#likelihood(np.array([2,2]), np.array([2, 2, 0, 0, 0, 0]), np.array([1, 1.2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba79537",
   "metadata": {},
   "source": [
    "## ~Prior~\n",
    "$$p(\\theta_i)$$\n",
    "Assumed to be gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96748c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(theta):\n",
    "    mean, A = theta_to_params(theta)\n",
    "    return np.exp(stable_multivariate_gaussian_logpdf(mean, mean_prior, cov_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56baf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior(np.array([2, 5, 0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b0ffb",
   "metadata": {},
   "source": [
    "## Optimizer for posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966c886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(f, x0, gradient, callback=lambda x: x, rate=0.5, iters=1e5):\n",
    "    x = x0\n",
    "    running_average = []\n",
    "    for i in range(int(iters)):\n",
    "        r = rate/(1+i*1e-1)\n",
    "        print('------')\n",
    "        print(r)\n",
    "        g = gradient(x)\n",
    "        print(np.linalg.norm(g))\n",
    "        x = -g * r + x\n",
    "        if i % 1 == 0:\n",
    "            if not callback(x):\n",
    "                break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75afc0a5",
   "metadata": {},
   "source": [
    "# Log-Posterior\n",
    "$$\\log p(\\theta_i | \\textbf{y}, \\textbf{d})$$\n",
    "We try to approximate this by our variational distribution $q(\\theta) \\sim \\mathcal{N}(\\mu_\\theta, \\Sigma_\\theta)$ such that $$p(\\theta_i | \\textbf{y}, \\textbf{d}) \\approx \\mathcal{N}(\\theta_i, \\mu_\\theta, \\Sigma_\\theta)$$.\n",
    "Thus we first optimize to find $\\mu_\\theta$ and $\\Sigma_\\theta$ and then we evalute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160022dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_mean = None\n",
    "cached_A = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393114c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "def log_posterior(weights, y, d, mean0=mean_prior, A0 = A_prior):\n",
    "    def objective_f(x):\n",
    "        mean, A = theta_to_params(x)\n",
    "        return - elbo(mean, A, y, d) + np.linalg.norm(x)\n",
    "    def callback(xi):\n",
    "        mean, A = theta_to_params(xi)\n",
    "        #print(np.linalg.norm(gradient(xi)))\n",
    "        thetas.append(mean)\n",
    "        if np.linalg.norm(gradient(xi)) < 7 and np.mean(np.square(y - d @ mean)) < 1:\n",
    "            return False\n",
    "        return True\n",
    "    gradient = grad(objective_f)\n",
    "    results = optimizer(objective_f, params_to_theta(mean0, A0), gradient, callback=callback, rate=0.5)\n",
    "    mean, A = theta_to_params(results)\n",
    "    cached_mean = mean\n",
    "    cached_A = A\n",
    "    return stable_multivariate_gaussian_logpdf(weights, mean, A @ A.T), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c84b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "0.5\n",
      "7.996102188081079\n",
      "------\n",
      "0.45454545454545453\n",
      "9.645228459317371\n",
      "------\n",
      "0.4166666666666667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m xs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m20\u001b[39m), np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m20\u001b[39m)])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      3\u001b[0m ys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m]]) \u001b[38;5;241m@\u001b[39m xs\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m----> 4\u001b[0m res, x \u001b[38;5;241m=\u001b[39m \u001b[43mlog_posterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m mean, A \u001b[38;5;241m=\u001b[39m theta_to_params(x)\n\u001b[1;32m      6\u001b[0m cached_mean \u001b[38;5;241m=\u001b[39m mean\n",
      "Cell \u001b[0;32mIn[51], line 14\u001b[0m, in \u001b[0;36mlog_posterior\u001b[0;34m(weights, y, d, mean0, A0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m gradient \u001b[38;5;241m=\u001b[39m grad(objective_f)\n\u001b[0;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_to_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m mean, A \u001b[38;5;241m=\u001b[39m theta_to_params(results)\n\u001b[1;32m     16\u001b[0m cached_mean \u001b[38;5;241m=\u001b[39m mean\n",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m, in \u001b[0;36moptimizer\u001b[0;34m(f, x0, gradient, callback, rate, iters)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(r)\n\u001b[0;32m----> 8\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(g))\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mg \u001b[38;5;241m*\u001b[39m r \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/differential_operators.py:28\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(fun, x):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Returns a function which computes the gradient of `fun` with respect to\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    positional argument number `argnum`. The returned function takes the same\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    arguments as `fun`, but returns the gradient instead. The function `fun`\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    should be scalar-valued. The gradient has the same type as the argument.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[1;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[0;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[0;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m, in \u001b[0;36mlog_posterior.<locals>.objective_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective_f\u001b[39m(x):\n\u001b[1;32m      4\u001b[0m     mean, A \u001b[38;5;241m=\u001b[39m theta_to_params(x)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m \u001b[43melbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "Cell \u001b[0;32mIn[24], line 50\u001b[0m, in \u001b[0;36melbo\u001b[0;34m(mean, A, y, d)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(lik)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mlen\u001b[39m(values))\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m KLD(mean, A, mean_prior, A_prior)\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/numpy/numpy_boxes.py:25\u001b[0m, in \u001b[0;36mArrayBox.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/tracer.py:45\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     argnums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(argnum    \u001b[38;5;28;01mfor\u001b[39;00m argnum, _   \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[1;32m     44\u001b[0m     ans \u001b[38;5;241m=\u001b[39m f_wrapped(\u001b[38;5;241m*\u001b[39margvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 45\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[43mnode_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/core.py:36\u001b[0m, in \u001b[0;36mVJPNode.__init__\u001b[0;34m(self, value, fun, args, kwargs, parent_argnums, parents)\u001b[0m\n\u001b[1;32m     33\u001b[0m     fun_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fun, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, fun)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVJP of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m wrt argnums \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m                               \u001b[38;5;241m.\u001b[39mformat(fun_name, parent_argnums))\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;241m=\u001b[39m \u001b[43mvjpmaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/core.py:76\u001b[0m, in \u001b[0;36mdefvjp.<locals>.vjp_argnums\u001b[0;34m(argnums, ans, args, kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVJP of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m wrt argnums 0, 1 not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fun\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m---> 76\u001b[0m vjp_0 \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_0_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m vjp_1 \u001b[38;5;241m=\u001b[39m vjp_1_fun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: (vjp_0(g), vjp_1(g))\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/numpy/numpy_vjps.py:32\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ans, x, y)\u001b[0m\n\u001b[1;32m     28\u001b[0m defvjp(anp\u001b[38;5;241m.\u001b[39mnan_to_num, \u001b[38;5;28;01mlambda\u001b[39;00m ans, x: \u001b[38;5;28;01mlambda\u001b[39;00m g: anp\u001b[38;5;241m.\u001b[39mwhere(anp\u001b[38;5;241m.\u001b[39misfinite(x), g, \u001b[38;5;241m0.\u001b[39m))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ----- Binary ufuncs -----\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m defvjp(anp\u001b[38;5;241m.\u001b[39madd,         \u001b[38;5;28;01mlambda\u001b[39;00m ans, x, y : \u001b[43munbroadcast_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     33\u001b[0m                         \u001b[38;5;28;01mlambda\u001b[39;00m ans, x, y : unbroadcast_f(y, \u001b[38;5;28;01mlambda\u001b[39;00m g: g))\n\u001b[1;32m     34\u001b[0m defvjp(anp\u001b[38;5;241m.\u001b[39mmultiply,    \u001b[38;5;28;01mlambda\u001b[39;00m ans, x, y : unbroadcast_f(x, \u001b[38;5;28;01mlambda\u001b[39;00m g: y \u001b[38;5;241m*\u001b[39m g),\n\u001b[1;32m     35\u001b[0m                         \u001b[38;5;28;01mlambda\u001b[39;00m ans, x, y : unbroadcast_f(y, \u001b[38;5;28;01mlambda\u001b[39;00m g: x \u001b[38;5;241m*\u001b[39m g))\n\u001b[1;32m     36\u001b[0m defvjp(anp\u001b[38;5;241m.\u001b[39msubtract,    \u001b[38;5;28;01mlambda\u001b[39;00m ans, x, y : unbroadcast_f(x, \u001b[38;5;28;01mlambda\u001b[39;00m g: g),\n\u001b[1;32m     37\u001b[0m                         \u001b[38;5;28;01mlambda\u001b[39;00m ans, x, y : unbroadcast_f(y, \u001b[38;5;28;01mlambda\u001b[39;00m g: \u001b[38;5;241m-\u001b[39mg))\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/numpy/numpy_vjps.py:658\u001b[0m, in \u001b[0;36munbroadcast_f\u001b[0;34m(target, f)\u001b[0m\n\u001b[1;32m    655\u001b[0m         x \u001b[38;5;241m=\u001b[39m anp\u001b[38;5;241m.\u001b[39mreal(x)\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munbroadcast_f\u001b[39m(target, f):\n\u001b[1;32m    659\u001b[0m     target_meta \u001b[38;5;241m=\u001b[39m anp\u001b[38;5;241m.\u001b[39mmetadata(target)\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: unbroadcast(f(g), target_meta)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thetas = []\n",
    "xs = np.array([np.linspace(0, 100, 20), np.ones(20)]).T\n",
    "ys = np.array([[2,1]]) @ xs.T\n",
    "res, x = log_posterior(mean_prior, ys, xs, mean0=cached_mean, A0=cached_A)\n",
    "mean, A = theta_to_params(x)\n",
    "cached_mean = mean\n",
    "cached_A = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a083df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "0.5\n",
      "291.8199843617202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mreshape(d, (d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)), ones), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, size\u001b[38;5;241m=\u001b[39ml)\u001b[38;5;241m.\u001b[39mreshape([l, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m true_weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m d[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape([l,\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m true_weights[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m \u001b[43mlog_posterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 14\u001b[0m, in \u001b[0;36mlog_posterior\u001b[0;34m(weights, y, d, mean0, A0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m gradient \u001b[38;5;241m=\u001b[39m grad(objective_f)\n\u001b[0;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_to_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m mean, A \u001b[38;5;241m=\u001b[39m theta_to_params(results)\n\u001b[1;32m     16\u001b[0m cached_mean \u001b[38;5;241m=\u001b[39m mean\n",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m, in \u001b[0;36moptimizer\u001b[0;34m(f, x0, gradient, callback, rate, iters)\u001b[0m\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mg \u001b[38;5;241m*\u001b[39m r \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[51], line 10\u001b[0m, in \u001b[0;36mlog_posterior.<locals>.callback\u001b[0;34m(xi)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#print(np.linalg.norm(gradient(xi)))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m thetas\u001b[38;5;241m.\u001b[39mappend(mean)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m7\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msquare(y \u001b[38;5;241m-\u001b[39m d \u001b[38;5;241m@\u001b[39m mean)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/differential_operators.py:32\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[0;34m(g)\u001b[0m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/core.py:21\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m toposort(end_node):\n\u001b[1;32m     20\u001b[0m     outgrad \u001b[38;5;241m=\u001b[39m outgrads\u001b[38;5;241m.\u001b[39mpop(node)\n\u001b[0;32m---> 21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[1;32m     23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m add_outgrads(outgrads\u001b[38;5;241m.\u001b[39mget(parent), ingrad)\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/core.py:67\u001b[0m, in \u001b[0;36mdefvjp.<locals>.vjp_argnums.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVJP of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m wrt argnum 0 not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fun\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[1;32m     66\u001b[0m     vjp \u001b[38;5;241m=\u001b[39m vjpfun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: (\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m,)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m L \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     69\u001b[0m     argnum_0, argnum_1 \u001b[38;5;241m=\u001b[39m argnums\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/numpy/linalg.py:39\u001b[0m, in \u001b[0;36mgrad_inv.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_inv\u001b[39m(ans, x):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: \u001b[38;5;241m-\u001b[39m_dot(\u001b[43m_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m, T(ans))\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Programs/assignments/pocs/python/venv/lib/python3.10/site-packages/numpy/core/einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[1;32m   1370\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_ = 2\n",
    "l = 300\n",
    "np.random.seed(612635)\n",
    "true_weights = np.array([-9, 15])\n",
    "\n",
    "noise = 2\n",
    "\n",
    "d = np.random.rand(l)\n",
    "ones = np.ones((d.shape[0], 1))\n",
    "d = np.concatenate((np.reshape(d, (d.shape[0], 1)), ones), axis=1)\n",
    "y = np.random.normal(loc = 0, scale=2, size=l).reshape([l, 1]) + true_weights[0] * d[:, 0].reshape([l,1]) + true_weights[1]\n",
    "log_posterior(mean_prior, y, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c38708d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5b5da4ef50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([2], [1])\n",
    "plt.scatter(thetas[0][0], thetas[0][1])\n",
    "plt.scatter(np.array(thetas)[:, 0], np.array(thetas)[:, 1], alpha=[10/(10 + i) for i, t in enumerate(thetas)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568f20f",
   "metadata": {},
   "source": [
    "# Gradient of Log-Likelihood\n",
    "$$\\frac{\\partial }{\\partial \\textbf{d}} \\log p(\\theta_i | \\textbf{y}, \\textbf{d})$$\n",
    "$$= c + \\frac{1}{N}\\sum_{i=1}^Np(\\textbf{y}|\\theta_i, \\textbf{d})p(\\theta_i)\\frac{\\partial }{\\partial \\textbf{d}}\\log p(\\theta_i |\\textbf{y}, \\textbf{d})(\\log p(\\theta_i |\\textbf{y}, \\textbf{d}) + 1)$$\n",
    "Based on Lorraine19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fb093c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_log_likelihood(log_q, theta_i, y, d):\n",
    "    # samples = 20\n",
    "    # theta_samples = np.random.multivariate_normal(mean_prior, A_prior @ A_prior.T, size=samples)\n",
    "    return grad(log_q(theta_i))()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a54814d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5846827743834317e-46"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log_likelihood(1,ys,xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
